{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd318e9f",
   "metadata": {},
   "source": [
    "# Lab 3.1 Knowledge Graph\n",
    "\n",
    "Il seguente esercizio prevede la costruzione di un grafo memorizzato su Neo4j e una semplice implementazione per visualizzarne i dati:\n",
    "    \n",
    "Il grafo sarà costruito come segue: a partire da un testo verranno estratte tutte le triple Soggetto - Verbo - Oggetto, per ogni componente della tripla saranno estratti i synset di Wordnet e verranno usati come nodi del nostro grafo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110ffd19",
   "metadata": {},
   "source": [
    "### Il documento di partenza\n",
    "\n",
    "Usiamo come documento lo stesso dell'esercizio 2.1 che era stato creando mescolando due testi: uno sulla guerra e uno sul cucinare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45f678c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import nltk\n",
    "\n",
    "title_document = 'input_ex_2_1-Copy1.TXT'\n",
    "\n",
    "with open(title_document, 'r') as file:\n",
    "    input_document = file.read()\n",
    "\n",
    "input_document = nltk.sent_tokenize(input_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6669014d",
   "metadata": {},
   "source": [
    "### Metodo: Extract SVO\n",
    "\n",
    "Il seguente metodo, data una frase in input, restituisce una lista di triple Soggetto - Verbo - Oggetto trovate in essa.\n",
    "\n",
    "Per questa fase si utilizza la libreria di spacy in fase di parsing e un modulo importato per l'estrazione delle triple `findSVOs`\n",
    "\n",
    "Per via dell'ambiguità delle frasi possono essere individuati più soggetti e oggetti quindi il metodo restituirà una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5d8cc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dog', 'eat', 'apple')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from subject_object_extraction import findSVOs\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_svo(input_sentence):\n",
    "    doc = nlp(input_sentence)\n",
    "    return findSVOs(doc)\n",
    "\n",
    "# Example \n",
    "print(extract_svo(\"The dog eat an apple\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750ffff1",
   "metadata": {},
   "source": [
    "### I Synset di worndet\n",
    "\n",
    "Per l'estrazione dei synset sarà utilizzato l'algoritmo di disambiguazione delle librerie nltk `Lesk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e73251a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('pawl.n.01')\n",
      "Synset('apple.n.02')\n",
      "Synset('eat.v.04')\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.wsd import lesk\n",
    "\n",
    "def extract_synset_noun(word, sent):\n",
    "    return lesk(sent, word, 'n')\n",
    "\n",
    "def extract_synset_verb(word, sent):\n",
    "    return lesk(sent, word, 'v')\n",
    "\n",
    "# Example\n",
    "print(extract_synset_noun('dog', \"The dog eat an apple\"))\n",
    "print(extract_synset_noun('apple', \"The dog eat an apple\"))\n",
    "print(extract_synset_verb('eat', \"The dog eat an apple\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fdd635",
   "metadata": {},
   "source": [
    "### Neo4j\n",
    "\n",
    "Definiamo seguentemente i metodi per connettersi e costruire le nostre query nel database `neo4j` installato in locale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c312f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from neo4j.exceptions import ServiceUnavailable\n",
    "\n",
    "uri = 'bolt://localhost:7687'\n",
    "driver = GraphDatabase.driver(uri)\n",
    "\n",
    "def create_synset(tx, synset_id):\n",
    "    return tx.run(\"CREATE (:Synset {syn_id: $id})\", id=synset_id)\n",
    "\n",
    "# l'uso di merge permette di creare il nodo qual'ora non esistesse\n",
    "def create_relationship_sub_verb(tx, syn1, syn2):\n",
    "    s1_lemmas = [l.name() for l in syn1.lemmas()]\n",
    "    s2_lemmas = [l.name() for l in syn2.lemmas()]\n",
    "    tx.run(\"MERGE (s1:Synset {syn_id: $s1_id, lemmas: $s1_lemmas, definition: $s1_def}) \"\n",
    "               \"MERGE (s2:Synset  {syn_id: $s2_id, lemmas: $s2_lemmas, definition: $s2_def}) \"\n",
    "               \"MERGE (s1)-[:SUBJ_OF]->(s2)\",\n",
    "               s1_id=syn1.offset(), s2_id=syn2.offset(),\n",
    "                s1_lemmas=s1_lemmas, s2_lemmas=s2_lemmas,\n",
    "                s1_def= syn1.definition(), s2_def=syn2.definition())\n",
    "\n",
    "    \n",
    "def create_relationship_verb_obj(tx, syn1, syn2):\n",
    "    s1_lemmas = [l.name() for l in syn1.lemmas()]\n",
    "    s2_lemmas = [l.name() for l in syn2.lemmas()]\n",
    "    tx.run(\"MERGE (s1:Synset {syn_id: $s1_id, lemmas: $s1_lemmas, definition: $s1_def}) \"\n",
    "               \"MERGE (s2:Synset  {syn_id: $s2_id, lemmas: $s2_lemmas, definition: $s2_def}) \"\n",
    "               \"MERGE (s1)-[:HAS_OBJ]->(s2)\",\n",
    "               s1_id=syn1.offset(), s2_id=syn2.offset(),\n",
    "                s1_lemmas=s1_lemmas, s2_lemmas=s2_lemmas,\n",
    "                s1_def= syn1.definition(), s2_def=syn2.definition())\n",
    "\n",
    "# metodo per resettare il database 'tln'\n",
    "def reset():\n",
    "    try:\n",
    "        with driver.session(database='tln') as session:\n",
    "            session.write_transaction(lambda tx: tx.run(\"MATCH (n) DETACH DELETE n\"))\n",
    "        return True\n",
    "    except ServiceUnavailable:\n",
    "        return False\n",
    "    \n",
    "\n",
    "# metodo per memorizzare le relazioni:\n",
    "# sog - subj of - verb / verb - has obj - obj\n",
    "def save_triple(subj, verb, obj):\n",
    "    try:\n",
    "        with driver.session(database='tln') as session:\n",
    "            session.write_transaction(lambda tx: create_relationship_sub_verb(tx, subj, verb))\n",
    "            session.write_transaction(lambda tx: create_relationship_verb_obj(tx, verb, obj))\n",
    "        return True\n",
    "    except ServiceUnavailable:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742881e8",
   "metadata": {},
   "source": [
    "### Riempiamo il database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0cd76107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset()\n",
    "\n",
    "# Per ogni frase\n",
    "for sent in input_document:\n",
    "    triples = extract_svo(sent)\n",
    "    \n",
    "    # Per ogni tripla estratta -> creo le relazioni in db\n",
    "    for t in triples:\n",
    "        sub = extract_synset_noun(t[0],sent)\n",
    "        verb = extract_synset_verb(t[1],sent)\n",
    "        obj =extract_synset_noun(t[2], sent)\n",
    "        save_triple(sub, verb, obj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa4b8c2",
   "metadata": {},
   "source": [
    "### Visualizzazione \n",
    "\n",
    "Usiamo la libreria `graphistry`, la quale sfrutta un server online per creare una visualizzazione diretta di `neo4j`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "625cc41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphistry\n",
    "import pandas as pd\n",
    "NEO4J = {\n",
    "    'uri':uri,\n",
    "    'database':'tln'\n",
    "}\n",
    "graphistry.register(bolt=GraphDatabase.driver(**NEO4J), api=3, protocol=\"https\", server=\"hub.graphistry.com\", token=\"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VybmFtZSI6InBlcDEyMyIsImlhdCI6MTYzMDQ0ODI3MSwiZXhwIjoxNjMwNDUxODcxLCJqdGkiOiJiMDM0ZDQ0OC0zNzM5LTRkZWEtYmRiYS0zYjkzMDc0YjcwOWQiLCJ1c2VyX2lkIjo1NTg2LCJvcmlnX2lhdCI6MTYzMDQ0ODI3MX0._31L6p_l6Sa8LJIDIK-yWMqYWuMygNS0WkU4wM0ldHw\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "58d95da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed memoization speedup attempt due to Pandas internal hash function failing. Continuing without memoization speedups.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <iframe id=\"c39f624f-5094-4620-a559-134bd956784e\" src=\"https://hub.graphistry.com/graph/graph.html?dataset=cf4e49090bbd49bcb1e682234886aebd&type=arrow&viztoken=cf201036-2f39-4e63-b390-77328ea2c3c5&usertag=588436f7-pygraphistry-0.20.1&splashAfter=1630451696&info=true\"\n",
       "                    allowfullscreen=\"true\" webkitallowfullscreen=\"true\" mozallowfullscreen=\"true\"\n",
       "                    oallowfullscreen=\"true\" msallowfullscreen=\"true\"\n",
       "                    style=\"width:100%; height:500px; border: 1px solid #DDD; overflow: hidden\">\n",
       "            </iframe>\n",
       "        \n",
       "            <script>\n",
       "                try {\n",
       "                  $(\"#c39f624f-5094-4620-a559-134bd956784e\").bind('mousewheel', function(e) { e.preventDefault(); });\n",
       "                } catch (e) { console.error('exn catching scroll', e); }\n",
       "            </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query soggetto - subj of - verbo\n",
    "SUBJ_OF = 'MATCH (a)-[r:SUBJ_OF]->(b)  RETURN a, r, b'\n",
    "# query verbo - has obj - oggetto\n",
    "HAS_OBJ = 'MATCH (a)-[r:HAS_OBJ]->(b)  RETURN a, r, b'\n",
    "# query all in\n",
    "ALL = 'MATCH (a)-[r]->(b)  RETURN a, r, b'\n",
    "\n",
    "g = graphistry.cypher(ALL)\n",
    "g.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb537182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
